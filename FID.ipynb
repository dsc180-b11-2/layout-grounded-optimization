{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fafe7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytorch-fid\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5996b3e",
   "metadata": {},
   "source": [
    "# Image Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63aa75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images_in_folder(input_folder, output_folder, target_size, size = 1e5):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    count = 0\n",
    "    # Loop through all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')) and count < size:  # Add more file extensions if needed\n",
    "            # Open image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            with Image.open(image_path) as img:\n",
    "                # Convert to RGB if image has alpha channel\n",
    "                if img.mode == 'RGBA':\n",
    "                    img = img.convert('RGB')\n",
    "                # Resize image\n",
    "                resized_img = img.resize(target_size, resample=Image.LANCZOS)\n",
    "                # Save resized image to output folder\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                resized_img.save(output_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5b3f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape dog dataset\n",
    "input_folder = \"dog\"\n",
    "output_folder = \"dog_256_256\"\n",
    "target_size = (256, 256)  # Specify your target size here\n",
    "\n",
    "resize_images_in_folder(input_folder, output_folder, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"dogs\"\n",
    "output_folder = \"sample_dog\"\n",
    "target_size = (256, 256)  # Specify your target size here\n",
    "\n",
    "resize_images_in_folder(input_folder, output_folder, target_size,size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape flower\n",
    "input_folder = \"flower\"\n",
    "output_folder = \"flower_256\"\n",
    "target_size = (256, 256)  # Specify your target size here\n",
    "\n",
    "resize_images_in_folder(input_folder, output_folder, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape flower\n",
    "input_folder = \"flower\"\n",
    "output_folder = \"sample_flower\"\n",
    "target_size = (256, 256)  # Specify your target size here\n",
    "\n",
    "resize_images_in_folder(input_folder, output_folder, target_size,size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce396ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from random import sample\n",
    "\n",
    "def move_random_images(source_dir, destination_dir, n=1000):\n",
    "    \"\"\"\n",
    "    Move n random images from the source directory to the destination directory.\n",
    "\n",
    "    Parameters:\n",
    "    - source_dir: The path to the source directory containing the images.\n",
    "    - destination_dir: The path to the destination directory where the images will be moved.\n",
    "    - n: The number of images to move. Default is 1000.\n",
    "\n",
    "    Returns:\n",
    "    - A message indicating success or failure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if source directory exists\n",
    "    if not os.path.isdir(source_dir):\n",
    "        return \"Source directory does not exist.\"\n",
    "\n",
    "    # Create destination directory if it doesn't exist\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "    # Get all image files in the source directory\n",
    "    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "    \n",
    "    # Ensure there are enough images to sample\n",
    "    if len(files) < n:\n",
    "        return f\"Source directory has only {len(files)} files, which is less than {n}.\"\n",
    "\n",
    "    # Sample n images randomly\n",
    "    selected_files = sample(files, n)\n",
    "\n",
    "    # Move the selected images to the destination directory\n",
    "    for file in selected_files:\n",
    "        shutil.move(os.path.join(source_dir, file), os.path.join(destination_dir, file))\n",
    "\n",
    "    return \"Successfully moved 1000 random images to the new folder.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'dog_256_256'\n",
    "destination_dir = 'sample_dog'\n",
    "result = move_random_images(source_dir, destination_dir)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'flower_256'\n",
    "destination_dir = 'sample_flower'\n",
    "result = move_random_images(source_dir, destination_dir)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebbe83",
   "metadata": {},
   "source": [
    "## Dog Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baac64e",
   "metadata": {},
   "source": [
    "Dog dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8607f377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19580\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"dog_256_256\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af7de0a",
   "metadata": {},
   "source": [
    "### Benchmark: Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81455e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"sample_dog\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7fa54f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /tmp/xdg-cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
      "100%|███████████████████████████████████████| 91.2M/91.2M [00:00<00:00, 223MB/s]\n",
      "100%|█████████████████████████████████████████| 392/392 [00:23<00:00, 16.60it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.48it/s]\n",
      "FID:  19.655424052591513\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid dog_256_256 sample_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860f59f",
   "metadata": {},
   "source": [
    "### Benchmark: flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17105104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"sample_flower\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418c9b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 295/295 [00:18<00:00, 16.38it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.41it/s]\n",
      "FID:  19.949964977776858\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid flower_256 sample_flower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4092189",
   "metadata": {},
   "source": [
    "### r = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e6e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0/img_generations/dog_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9537ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 392/392 [00:23<00:00, 16.56it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.07it/s]\n",
      "FID:  117.61440104851346\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid dog_256_256 \"LLM-groundedDiffusion-main r=0/img_generations/dog_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eed7bf",
   "metadata": {},
   "source": [
    "### r = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988f8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0.5/img_generations/dog_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff9a0a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 392/392 [00:24<00:00, 16.04it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.15it/s]\n",
      "FID:  117.30277797733805\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid dog_256_256 \"LLM-groundedDiffusion-main r=0.5/img_generations/dog_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd3f8d",
   "metadata": {},
   "source": [
    "### r = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae13efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0.25/img_generations/dog_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9e06a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 392/392 [00:23<00:00, 16.76it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.53it/s]\n",
      "FID:  117.41795372253074\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid dog_256_256 \"LLM-groundedDiffusion-main r=0.25/img_generations/dog_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d424b",
   "metadata": {},
   "source": [
    "### r = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e63593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0.75/img_generations/dog_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51fc31fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 392/392 [00:23<00:00, 16.69it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.08it/s]\n",
      "FID:  118.43943972262153\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid dog_256_256 \"LLM-groundedDiffusion-main r=0.75/img_generations/dog_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f8d18",
   "metadata": {},
   "source": [
    "### r= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb49b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=1/img_generations/dog_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b66be458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 392/392 [00:23<00:00, 16.57it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 10.60it/s]\n",
      "FID:  118.6913236422723\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid dog_256_256 \"LLM-groundedDiffusion-main r=1/img_generations/dog_256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_fid = {0:117.44714904357238,0.25:117.26509443515633,0.5:117.15055286517696,0.75:,1:118.54028340533469}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b090bb",
   "metadata": {},
   "source": [
    "## Flower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9cf8f",
   "metadata": {},
   "source": [
    "Flower data site size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca932cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14740\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"flower_256\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a9251",
   "metadata": {},
   "source": [
    "### Benchmark: sample flower to dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f4c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 392/392 [00:23<00:00, 16.74it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.93it/s]\n",
      "FID:  218.16071001400854\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid dog_256_256 sample_flower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f12a52",
   "metadata": {},
   "source": [
    "### Benchmark: sample dog to flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2ee6c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 295/295 [00:18<00:00, 16.23it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.57it/s]\n",
      "FID:  217.3830488089513\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid flower_256 sample_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87625d",
   "metadata": {},
   "source": [
    "### r = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e9adb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0/img_generations/flower_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecaf5e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 295/295 [00:18<00:00, 16.23it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.25it/s]\n",
      "FID:  127.6799754670075\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid flower_256 \"LLM-groundedDiffusion-main r=0/img_generations/flower_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee2edc",
   "metadata": {},
   "source": [
    "### r = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ac92382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0.25/img_generations/flower_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe437df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 295/295 [00:18<00:00, 16.27it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 10.72it/s]\n",
      "FID:  119.58722892537781\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid flower_256 \"LLM-groundedDiffusion-main r=0.25/img_generations/flower_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a239753",
   "metadata": {},
   "source": [
    "### r = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09012e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0.5/img_generations/flower_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b635db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 295/295 [00:18<00:00, 16.21it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.16it/s]\n",
      "FID:  116.79505359959273\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid flower_256 \"LLM-groundedDiffusion-main r=0.5/img_generations/flower_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89c30b",
   "metadata": {},
   "source": [
    "### r = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef784606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=0.75/img_generations/flower_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "338186c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 295/295 [00:18<00:00, 16.11it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.02it/s]\n",
      "FID:  115.70124442540322\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid flower_256 \"LLM-groundedDiffusion-main r=0.75/img_generations/flower_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ebf7d",
   "metadata": {},
   "source": [
    "### r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "996b988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 \"LLM-groundedDiffusion-main r=1/img_generations/flower_256\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eced0e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 295/295 [00:18<00:00, 16.21it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 11.22it/s]\n",
      "FID:  115.9511580373192\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_fid flower_256 \"LLM-groundedDiffusion-main r=1/img_generations/flower_256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea871e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_fid = {0:117.44714904357238,0.25:117.26509443515633,0.5:117.15055286517696,0.75:117,1:118.54028340533469}\n",
    "flower_fid = {0:127.65133555359535,0.25:119.55554361497246,0.5:116.7668729775477,0.75:117,1:115.9354636386953}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d219d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([dog_fid, flower_fid]).T\n",
    "df = df.reset_index()\n",
    "df.columns = ['frozen step ratio $$r$$','dog', 'flower']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df, x = 'frozen step ratio $$r$$', y = 'Fréchet Inception Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695cfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
