<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Beyond Text-to-Image: Layout-grounded Stable Diffusion Optimization </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LaTeX Math in HTML with MathJax</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-1 publication-title" style="font-size: x-large;">Beyond Text-to-Image:</h2><h1 class="title is-1 publication-title" style="font-size: xxx-large;">Layout-Grounded Stable Diffusion Optimization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a >Jiatu Li<sup>1</sup></a>,</span>
            <span class="author-block">
              <a href="https://wantingmao01.github.io/">Wanting Mao<sup>1</sup></a>,</span>
            <span class="author-block">
              <a >Zhengyun Nie<sup>1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/jesswsong/">Jessica Song<sup>1</sup></a>
            </span>,
            <span class="author-block">
              <a href="https://sites.google.com/ucsd.edu/alexandercloninger/home">Alex Cloninger<sup>1,*</sup></a>
            </span>,
            <span class="author-block">
              <a href="https://mathweb.ucsd.edu/~rsaab/">Rayan Saab<sup>1,*</sup></a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> University of California, San Diego</span>,
            <span class="author-block"><sup>*</sup>Mentor</span>
          </div>
          <div>
            <span class="author-block" style="font-size:medium;">Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Report</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/dsc180-b11-2/layout-grounded-optimization"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1LxQnwsxSMfa9k9hL2L7ujU7k-nmTEof6/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Poster</span>
                </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/gallery.png"
                 class="gallery"
                 alt="Comparison of DIL and previous methods"/>
      <h2 class="subtitle has-text-centered">
<span class="dnerf">Diffusion Image generation model based on Layout</span> offers precise control over object numeracy and location.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion models have been shown as the state-of-the-art methods to generate 
            realistic and diverse images based on text prompts, powering models like Stable Diffusion,
             MidJourney and DALL·E. However, stable diffusion still often make mistakes regarding 
             generating accurately according to numerical information and the object positions.
              This work proposes a new method to solve the object position problem by letting 
              users draw bounding boxes of objects to indicate their location, which to be used
               as part of the input, besides providing text prompts only. Our model then utilizes
                Layout-Grounded Stable Diffusion from 
                <a href="https://llm-grounded-diffusion.github.io/">Lian et al.</a> as the backbone to
                 solve the numeracy question so that the actual number of objects in the generated 
                 image could match the number specified in the original text prompt. By composing 
                 objects onto the positions specified by the user, our model can accurately generate
                  images with numerical and positional information coherent with the text prompt. 
                  Through our work, we identify the best coefficients for the above steps using Fréchet
                   Inception Distance. In addition, our model also introduces more diverse and specific
                    user input through integrating a canvas interface that supports specifying image 
                    generation subject location, size and color.
          </p>
        </div>
      </div>
    </div>

  </div>
</section> 

<!-- Results -->
<section class="section">
  <div class="container is-max-desktop">
    
    <h2 class="title is-3" style="text-align: center;">Results</h2>
    <div class="columns is-centered">
    

      <!-- Canvas -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Canvas</h2>
          <img src="./static/images/canvas_demo.png" 
          alt="Image of our Canvas Interface"/>
        </div>
      </div>

      <!-- Explanation -->
      <div class="column">
        <div class="columns is-centered vertically-centered">
          <div class="column content">
            <p>
              For our product, we utilize a canvas interface to introduce a creative artistic canvas for the user 
              to freely define a framework for their desired image. Through this canvas, you can draw bounding boxes 
              at desired locations and label the object whatever you want (e.g. a cat on the left). 
              Moreover, you can define the desired background of this photo (e.g. on grass).
              Lastly, you can also define the negative prompt - whatever you wish to not appear in the image. 
  
              After pressing the <code>Save Input</code> button, this canvas will generate a <code>.json</code> file. 
              This file can later be used to pass into the model. 
  
              Unfortunately, given our time and technical constraints, we weren't able to host the canvas interface along with the model on one server. This is a future development!
            </p>
          </div>

        </div>
      </div>
    </div>

    

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Optimization</h2>

        <h3 class="title is-4">Numerical Accuracy</h3>
        <div class="content has-text-justified">
            <p> We generated 500 images with prompts "A realistic image of one cup", "A realistic image of five cups", and "A realistic image of ten cups". The model can generate accurate images when the task is relatively simple. However, as the task is more demanding, the model is more likely to create more objects than needed or have two objects merged together.</p>
            <table>
              <caption style="font-style: italic;">Numerical Accuracy for Different Prompts</caption>
                <tr>
                    <th>r</th>
                    <th>One Cup</th>
                    <th>Five Cups</th>
                    <th>Ten Cups</th>
                </tr>
                <tr>
                  <td>0 (SDXL)</td>
                  <td>94.5%</td>
                  <td>10%</td>
                  <td>1.5%</td>
              </tr>
                <tr>
                    <td>0.75 (Ours)</td>
                    <td><b><em>99.4%</em></b></td>
                    <td><b><em>90.8%</em></b></td>
                    <td><b><em>53.6%</em></b></td>
                </tr>
            </table>
        </div>
        <div class="container is-max-desktop" style="margin-top: 40px;">
    
          <h3 class="title is-4">Image Quality</h3>
          <div class="content has-text-justified">
            <p> We generated 1000 images with fixed bounding boxes and varied frozen step ratio 
              \(r\) for two prompts: "A realistic image of a dog" and "A realistic image of a flower".
          </p>    
          </div>
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <figure>
                  <img src="./static/images/FID.png" 
                  style="text-align: center;" alt="FID with varying Frozen Step Ratio"/>
                  <figcaption>FID with varying Frozen Step Ratio</figcaption>
                </figure>
              </div>
            </div>
            <div class="column">
              <div class="columns is-centered">
                <div class="column content">
                  <figure>
                    <img src="./static/images/FID2.png" 
                    style="text-align: center;" alt="FID Zoom-in"/>
                    <figcaption>Zoom-in: FID Trend for two Prompts</figcaption>
                  </figure>
                </div>
      
              </div>
            </div>
          </div>
        </div>
 
  <!-- Numercial Accuracy Problems -->
        <div class="container is-max-desktop" style="margin-top: 40px;">
          <h3 class="title is-4">Numeracy Problems Analysis</h3>
          <div class="content has-text-justified">
            <p>  We noticed two major causes to decrease numerical accuracy in generated images:</p>    
          </div>
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <figure>
                  <img src="./static/images/num_prob_1.png" alt="An Example of Error Image"/>
                  <figcaption>Problem 1: Object Interaction</figcaption>
                </figure>
                <p style="text-align: center;">
                  Objects interact, causing a single masked latent to encapsulate multiple objects.
                </p>
              </div>
            </div>
            <div class="column">
              <div class="columns is-centered">
                <div class="column content">
                  <figure>
                    <img src="./static/images/num_prob_2.png" alt="An Example of Error Image"/>
                    <figcaption>Problem 2: Similar objects in background</figcaption>
                  </figure>
                  <p style="text-align: center;">
                    Diffusion model may use the prompt to produce similar objects in the background.                   </p>
                </div>

              </div>
            </div>
          </div>
        </div>
  </div>
</section>

<!-- Methods -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3" style="text-align: center;">Methods</h2>

    <h3 class="title is-4">Background: Layout-grounded Stable Diffusion</h3>
    <div class="content has-text-justified">
        <p><strong><em>Layout-grounded Generative Model</em></strong>, by 
          <a href="https://llm-grounded-diffusion.github.io/">Lian et al.</a>, 
          is a novel controller is introduced to 
          guide an existing diffusion model, such as Stable Diffusion, which originally 
          lacks this specific training objective. This guidance ensures adherence to the 
          layout generated in the initial phase. The process of generating the image in 
          this stage involves two main steps: generating masked latents for each object 
          specified in the layout (e.g., cats and dogs) with attention control to ensure 
          accurate placement within the designated boxes, followed by the coherent composition
           of these masked latents onto the background noisy image. This results in a final 
           image that aligns with the specified foreground and background based on the text
            prompt.
        </p>  
    </div>
    <figure style="text-align: center; margin-top: 40px;">
      <img src="./static/images/LMD Stage 2.png" alt="Layout-Grounded Stable Diffusion Workflow" width="700"/>
      <figcaption style="text-align: center;">Per-box masked latent generation tor instance-level 
        control (<a href="https://llm-grounded-diffusion.github.io/">Lian et al.</a>)</figcaption>
    </figure>
    <div style="margin-top: 40px;">
      <p>
        In the layout-grounded model, a critical parameter is <em><b>Frozen Step Ratio</b></em>, \(r\), which 
        represents the ratio of the number of time steps during which the masked latents
         and the background image are composed, to the total number of steps in the reverse 
         diffusion process.
      </p>
    </div>
    <div style="margin-top: 20px;">
      <div class="image-container">
        <img class = "flower-image" src="static/images/flower r=0.jpg" alt="r = 0">
        <img class = "flower-image" src="static/images/flower r = 0.25.jpg" alt="r = 0.25" >
        <img class = "flower-image" src="static/images/flower r = 0.5.jpg" alt="r = 0.5" >
        <img class = "flower-image" src="static/images/flower r = 0.75.jpg" alt="r = 0.75" >
        <img class = "flower-image" src="static/images/flower r = 1.jpg" alt="r = 1">
      </div>
      <div class="axis">
        <div class="point" style="left: 0%"></div>
        <div class="point" style="left: 25%;"></div>
        <div class="point" style="left: 50%;"></div>
        <div class="point" style="left: 75%;"></div>
        <div class="point" style="left: 100%;"></div>
        <div class="label" style="left: 0%">0</div>
        <div class="label" style="left: 0% ;bottom: -60px;">(SDXL)</div>
        <div class="label" style="left: 25%;">0.25</div>
        <div class="label" style="left: 50%;">0.5</div>
        <div class="label" style="left: 50%;bottom: -70px;">Frozen Step Ratio \(r\)</div>
        <div class="label" style="left: 75%;">0.75</div>
        <div class="label" style="left: 100%;">1</div>
        <div class="label" style="left: 100% ;bottom: -50px;">(Copy&Paste)</div>
      </div>
    </div>
    </div>
  </div>

</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <div style="background-color: #fafafa; padding: 20px;">
      <p>We would like to thank Professor Cloninger and Professor Saab for all the 
        instructions in the past two quarters. Thanks to Professor Suraj for leading 
        this wonderful capstone project, our TA Keng-Chi for his help. Last but not 
        least, thanks for the hard working DSMLP GPUs. 
      </p>
    </div>
  </div>
</section> 


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from <a href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
