{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open('http://streamlit.io')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2577e7d-7809-478c-ba14-dd910b8d0827",
   "metadata": {},
   "source": [
    "Run with gpt4 api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba7d9eb-da2b-4b02-8c8c-f90100b4330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using box scale: (512, 512)\n",
      "Not scaling the bounding box to fit the scene\n",
      "Using template: v0.1\n",
      "Cache: cache/cache_demo_v0.1_gpt-4.json\n",
      "Cache path: cache/cache_demo_v0.1_gpt-4.json\n",
      "Cache hit: Five cats sitting next to each other on the grass\n",
      "Cache miss: A thousand cats\n",
      "{'error': {'message': 'The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "{'error': {'message': 'The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "{'error': {'message': 'The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n",
      "Retrying after 1 minute\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/hd1/jwsong/LLM-groundedDiffusion/prompt_batch.py\", line 73, in <module>\n",
      "    resp = get_layout(prompt=prompt, llm_kwargs=llm_kwargs)\n",
      "  File \"/mnt/hd1/jwsong/LLM-groundedDiffusion/utils/llm.py\", line 83, in get_layout\n",
      "    time.sleep(60)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python prompt_batch.py --prompt-type demo --model gpt-4 --auto-query --always-save --template_version v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea9e67b-5b9b-4f19-bf67-48fba680ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using box scale: (512, 512)\n",
      "Not scaling the bounding box to fit the scene\n",
      "Using template: v0.1\n",
      "Cache: cache/cache_demo_v0.1_gpt-4.json\n",
      "Cache path: cache/cache_demo_v0.1_gpt-4.json\n",
      "Cache hit: Five cats sitting next to each other on the grass\n",
      "Cache miss: A hundred cat faces\n",
      "#########\n",
      "You are an intelligent bounding box generator. I will provide you with a caption for a photo, image, or painting. Your task is to generate the bounding boxes for the objects mentioned in the caption, along with a background prompt describing the scene. The images are of size 512x512. The top-left corner has coordinate [0, 0]. The bottom-right corner has coordinnate [512, 512]. The bounding boxes should not overlap or go beyond the image boundaries. Each bounding box should be in the format of (object name, [top-left x coordinate, top-left y coordinate, box width, box height]) and should not include more than one object. Do not put objects that are already provided in the bounding boxes into the background prompt. Do not include non-existing or excluded objects in the background prompt. Use \"A realistic scene\" as the background prompt if no background is given in the prompt. If needed, you can make reasonable guesses. Please refer to the example below for the desired format.\n",
      "\n",
      "Caption: A realistic image of landscape scene depicting a green car parking on the left of a blue truck, with a red air balloon and a bird in the sky\n",
      "Objects: [('a green car', [21, 281, 211, 159]), ('a blue truck', [269, 283, 209, 160]), ('a red air balloon', [66, 8, 145, 135]), ('a bird', [296, 42, 143, 100])]\n",
      "Background prompt: A realistic landscape scene\n",
      "Negative prompt: \n",
      "\n",
      "Caption: A realistic top-down view of a wooden table with two apples on it\n",
      "Objects: [('a wooden table', [20, 148, 472, 216]), ('an apple', [150, 226, 100, 100]), ('an apple', [280, 226, 100, 100])]\n",
      "Background prompt: A realistic top-down view\n",
      "Negative prompt: \n",
      "\n",
      "Caption: A realistic scene of three skiers standing in a line on the snow near a palm tree\n",
      "Objects: [('a skier', [5, 152, 139, 168]), ('a skier', [278, 192, 121, 158]), ('a skier', [148, 173, 124, 155]), ('a palm tree', [404, 105, 103, 251])]\n",
      "Background prompt: A realistic outdoor scene with snow\n",
      "Negative prompt: \n",
      "\n",
      "Caption: An oil painting of a pink dolphin jumping on the left of a steam boat on the sea\n",
      "Objects: [('a steam boat', [232, 225, 257, 149]), ('a jumping pink dolphin', [21, 249, 189, 123])]\n",
      "Background prompt: An oil painting of the sea\n",
      "Negative prompt: \n",
      "\n",
      "Caption: A cute cat and an angry dog without birds\n",
      "Objects: [('a cute cat', [51, 67, 271, 324]), ('an angry dog', [302, 119, 211, 228])]\n",
      "Background prompt: A realistic scene\n",
      "Negative prompt: birds\n",
      "\n",
      "Caption: Two pandas in a forest without flowers\n",
      "Objects: [('a panda', [30, 171, 212, 226]), ('a panda', [264, 173, 222, 221])]\n",
      "Background prompt: A forest\n",
      "Negative prompt: flowers\n",
      "\n",
      "Caption: An oil painting of a living room scene without chairs with a painting mounted on the wall, a cabinet below the painting, and two flower vases on the cabinet\n",
      "Objects: [('a painting', [88, 85, 335, 203]), ('a cabinet', [57, 308, 404, 201]), ('a flower vase', [166, 222, 92, 108]), ('a flower vase', [328, 222, 92, 108])]\n",
      "Background prompt: An oil painting of a living room scene\n",
      "Negative prompt: chairs\n",
      "\n",
      "Caption: A hundred cat faces\n",
      "Objects: \n",
      "#########\n",
      "Enter the response: ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/hd1/jwsong/LLM-groundedDiffusion/prompt_batch.py\", line 77, in <module>\n",
      "    parsed_input = parse_input_with_negative(text=resp, no_input=args.auto_query)\n",
      "  File \"/mnt/hd1/jwsong/LLM-groundedDiffusion/utils/parse.py\", line 73, in parse_input_with_negative\n",
      "    text = input(\"Enter the response: \")\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python prompt_batch.py --prompt-type demo --model gpt-4 --always-save --template_version v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79270b-b06e-4045-826c-526a622284fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3eaf79-fec2-4139-82c9-c63010d9b398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat face', [0, 0, 0, 0]), ('cat face', [0, 0, 51, 51]), ('cat face', [0, 0, 102, 102]), ('cat face', [0, 0, 153, 153]), ('cat face', [0, 0, 204, 204]), ('cat face', [0, 0, 255, 255]), ('cat face', [0, 0, 306, 306]), ('cat face', [0, 0, 357, 357]), ('cat face', [0, 0, 408, 408]), ('cat face', [0, 0, 459, 459]), ('cat face', [0, 0, 510, 510]), ('cat face', [51, 51, 0, 0]), ('cat face', [51, 51, 51, 51]), ('cat face', [51, 51, 102, 102]), ('cat face', [51, 51, 153, 153]), ('cat face', [51, 51, 204, 204]), ('cat face', [51, 51, 255, 255]), ('cat face', [51, 51, 306, 306]), ('cat face', [51, 51, 357, 357]), ('cat face', [51, 51, 408, 408]), ('cat face', [51, 51, 459, 459]), ('cat face', [51, 51, 510, 510]), ('cat face', [102, 102, 0, 0]), ('cat face', [102, 102, 51, 51]), ('cat face', [102, 102, 102, 102]), ('cat face', [102, 102, 153, 153]), ('cat face', [102, 102, 204, 204]), ('cat face', [102, 102, 255, 255]), ('cat face', [102, 102, 306, 306]), ('cat face', [102, 102, 357, 357]), ('cat face', [102, 102, 408, 408]), ('cat face', [102, 102, 459, 459]), ('cat face', [102, 102, 510, 510]), ('cat face', [153, 153, 0, 0]), ('cat face', [153, 153, 51, 51]), ('cat face', [153, 153, 102, 102]), ('cat face', [153, 153, 153, 153]), ('cat face', [153, 153, 204, 204]), ('cat face', [153, 153, 255, 255]), ('cat face', [153, 153, 306, 306]), ('cat face', [153, 153, 357, 357]), ('cat face', [153, 153, 408, 408]), ('cat face', [153, 153, 459, 459]), ('cat face', [153, 153, 510, 510]), ('cat face', [204, 204, 0, 0]), ('cat face', [204, 204, 51, 51]), ('cat face', [204, 204, 102, 102]), ('cat face', [204, 204, 153, 153]), ('cat face', [204, 204, 204, 204]), ('cat face', [204, 204, 255, 255]), ('cat face', [204, 204, 306, 306]), ('cat face', [204, 204, 357, 357]), ('cat face', [204, 204, 408, 408]), ('cat face', [204, 204, 459, 459]), ('cat face', [204, 204, 510, 510]), ('cat face', [255, 255, 0, 0]), ('cat face', [255, 255, 51, 51]), ('cat face', [255, 255, 102, 102]), ('cat face', [255, 255, 153, 153]), ('cat face', [255, 255, 204, 204]), ('cat face', [255, 255, 255, 255]), ('cat face', [255, 255, 306, 306]), ('cat face', [255, 255, 357, 357]), ('cat face', [255, 255, 408, 408]), ('cat face', [255, 255, 459, 459]), ('cat face', [255, 255, 510, 510]), ('cat face', [306, 306, 0, 0]), ('cat face', [306, 306, 51, 51]), ('cat face', [306, 306, 102, 102]), ('cat face', [306, 306, 153, 153]), ('cat face', [306, 306, 204, 204]), ('cat face', [306, 306, 255, 255]), ('cat face', [306, 306, 306, 306]), ('cat face', [306, 306, 357, 357]), ('cat face', [306, 306, 408, 408]), ('cat face', [306, 306, 459, 459]), ('cat face', [306, 306, 510, 510]), ('cat face', [357, 357, 0, 0]), ('cat face', [357, 357, 51, 51]), ('cat face', [357, 357, 102, 102]), ('cat face', [357, 357, 153, 153]), ('cat face', [357, 357, 204, 204]), ('cat face', [357, 357, 255, 255]), ('cat face', [357, 357, 306, 306]), ('cat face', [357, 357, 357, 357]), ('cat face', [357, 357, 408, 408]), ('cat face', [357, 357, 459, 459]), ('cat face', [357, 357, 510, 510]), ('cat face', [408, 408, 0, 0]), ('cat face', [408, 408, 51, 51]), ('cat face', [408, 408, 102, 102]), ('cat face', [408, 408, 153, 153]), ('cat face', [408, 408, 204, 204]), ('cat face', [408, 408, 255, 255]), ('cat face', [408, 408, 306, 306]), ('cat face', [408, 408, 357, 357]), ('cat face', [408, 408, 408, 408]), ('cat face', [408, 408, 459, 459]), ('cat face', [408, 408, 510, 510]), ('cat face', [459, 459, 0, 0]), ('cat face', [459, 459, 51, 51]), ('cat face', [459, 459, 102, 102]), ('cat face', [459, 459, 153, 153]), ('cat face', [459, 459, 204, 204]), ('cat face', [459, 459, 255, 255]), ('cat face', [459, 459, 306, 306]), ('cat face', [459, 459, 357, 357]), ('cat face', [459, 459, 408, 408]), ('cat face', [459, 459, 459, 459]), ('cat face', [459, 459, 510, 510]), ('cat face', [510, 510, 0, 0]), ('cat face', [510, 510, 51, 51]), ('cat face', [510, 510, 102, 102]), ('cat face', [510, 510, 153, 153]), ('cat face', [510, 510, 204, 204]), ('cat face', [510, 510, 255, 255]), ('cat face', [510, 510, 306, 306]), ('cat face', [510, 510, 357, 357]), ('cat face', [510, 510, 408, 408]), ('cat face', [510, 510, 459, 459]), ('cat face', [510, 510, 510, 510])]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_cat_coordinates(image_size, num_cats):\n",
    "    cat_coordinates = []\n",
    "    for i in range(0, image_size[0], image_size[0]//num_cats):\n",
    "        for j in range(0, image_size[1], image_size[1]//num_cats):\n",
    "            cat_coordinates.append(('cat face', [i,i,j,j]))\n",
    "    return cat_coordinates\n",
    "\n",
    "image_size = (512, 512)\n",
    "num_cats = 10\n",
    "cat_coordinates = generate_cat_coordinates(image_size, num_cats)\n",
    "\n",
    "print(cat_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70ff90f6-b491-4e0f-baa1-6d876a6498fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42fa8832-1d31-4216-9d74-99b5d5602ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a cat face', [0, 0, 51, 51]), ('a cat face', [51, 0, 102, 51]), ('a cat face', [102, 0, 153, 51]), ('a cat face', [153, 0, 204, 51]), ('a cat face', [204, 0, 255, 51]), ('a cat face', [255, 0, 306, 51]), ('a cat face', [306, 0, 357, 51]), ('a cat face', [357, 0, 408, 51]), ('a cat face', [408, 0, 459, 51]), ('a cat face', [459, 0, 510, 51]), ('a cat face', [0, 51, 51, 102]), ('a cat face', [51, 51, 102, 102]), ('a cat face', [102, 51, 153, 102]), ('a cat face', [153, 51, 204, 102]), ('a cat face', [204, 51, 255, 102]), ('a cat face', [255, 51, 306, 102]), ('a cat face', [306, 51, 357, 102]), ('a cat face', [357, 51, 408, 102]), ('a cat face', [408, 51, 459, 102]), ('a cat face', [459, 51, 510, 102]), ('a cat face', [0, 102, 51, 153]), ('a cat face', [51, 102, 102, 153]), ('a cat face', [102, 102, 153, 153]), ('a cat face', [153, 102, 204, 153]), ('a cat face', [204, 102, 255, 153]), ('a cat face', [255, 102, 306, 153]), ('a cat face', [306, 102, 357, 153]), ('a cat face', [357, 102, 408, 153]), ('a cat face', [408, 102, 459, 153]), ('a cat face', [459, 102, 510, 153]), ('a cat face', [0, 153, 51, 204]), ('a cat face', [51, 153, 102, 204]), ('a cat face', [102, 153, 153, 204]), ('a cat face', [153, 153, 204, 204]), ('a cat face', [204, 153, 255, 204]), ('a cat face', [255, 153, 306, 204]), ('a cat face', [306, 153, 357, 204]), ('a cat face', [357, 153, 408, 204]), ('a cat face', [408, 153, 459, 204]), ('a cat face', [459, 153, 510, 204]), ('a cat face', [0, 204, 51, 255]), ('a cat face', [51, 204, 102, 255]), ('a cat face', [102, 204, 153, 255]), ('a cat face', [153, 204, 204, 255]), ('a cat face', [204, 204, 255, 255]), ('a cat face', [255, 204, 306, 255]), ('a cat face', [306, 204, 357, 255]), ('a cat face', [357, 204, 408, 255]), ('a cat face', [408, 204, 459, 255]), ('a cat face', [459, 204, 510, 255]), ('a cat face', [0, 255, 51, 306]), ('a cat face', [51, 255, 102, 306]), ('a cat face', [102, 255, 153, 306]), ('a cat face', [153, 255, 204, 306]), ('a cat face', [204, 255, 255, 306]), ('a cat face', [255, 255, 306, 306]), ('a cat face', [306, 255, 357, 306]), ('a cat face', [357, 255, 408, 306]), ('a cat face', [408, 255, 459, 306]), ('a cat face', [459, 255, 510, 306]), ('a cat face', [0, 306, 51, 357]), ('a cat face', [51, 306, 102, 357]), ('a cat face', [102, 306, 153, 357]), ('a cat face', [153, 306, 204, 357]), ('a cat face', [204, 306, 255, 357]), ('a cat face', [255, 306, 306, 357]), ('a cat face', [306, 306, 357, 357]), ('a cat face', [357, 306, 408, 357]), ('a cat face', [408, 306, 459, 357]), ('a cat face', [459, 306, 510, 357]), ('a cat face', [0, 357, 51, 408]), ('a cat face', [51, 357, 102, 408]), ('a cat face', [102, 357, 153, 408]), ('a cat face', [153, 357, 204, 408]), ('a cat face', [204, 357, 255, 408]), ('a cat face', [255, 357, 306, 408]), ('a cat face', [306, 357, 357, 408]), ('a cat face', [357, 357, 408, 408]), ('a cat face', [408, 357, 459, 408]), ('a cat face', [459, 357, 510, 408]), ('a cat face', [0, 408, 51, 459]), ('a cat face', [51, 408, 102, 459]), ('a cat face', [102, 408, 153, 459]), ('a cat face', [153, 408, 204, 459]), ('a cat face', [204, 408, 255, 459]), ('a cat face', [255, 408, 306, 459]), ('a cat face', [306, 408, 357, 459]), ('a cat face', [357, 408, 408, 459]), ('a cat face', [408, 408, 459, 459]), ('a cat face', [459, 408, 510, 459]), ('a cat face', [0, 459, 51, 510]), ('a cat face', [51, 459, 102, 510]), ('a cat face', [102, 459, 153, 510]), ('a cat face', [153, 459, 204, 510]), ('a cat face', [204, 459, 255, 510]), ('a cat face', [255, 459, 306, 510]), ('a cat face', [306, 459, 357, 510]), ('a cat face', [357, 459, 408, 510]), ('a cat face', [408, 459, 459, 510]), ('a cat face', [459, 459, 510, 510])]\n"
     ]
    }
   ],
   "source": [
    "def generate_coordinates(image_size, rows, cols):\n",
    "    region_width = image_size[0] // cols\n",
    "    region_height = image_size[1] // rows\n",
    "    \n",
    "    coordinates = []\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "#             left_top = (j * region_width, i * region_height)\n",
    "#             right_bottom = ((j + 1) * region_width, (i + 1) * region_height)\n",
    "            coordinates.append(('a cat face', [j * region_width, i * region_height, \\\n",
    "                                             (j + 1) * region_width, (i + 1) * region_height]))\n",
    "    \n",
    "    return coordinates\n",
    "\n",
    "image_size = (512, 512)\n",
    "rows = 10\n",
    "cols = 10\n",
    "region_coordinates = generate_coordinates(image_size, rows, cols)\n",
    "\n",
    "print(region_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401edbc-7967-4c67-95e2-6bec3f73f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "[('cat', [100, 100, 0, 0]), ('cat', [0, 0, 120, 120]), ('cat', [255, 277, 345, 357]), ('cat', [150, 116, 221, 184]), ('cat', [96, 128, 150, 221])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
